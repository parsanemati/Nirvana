{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTI38I6hI5_T"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "07HYSelZyQmA",
    "outputId": "91beaa73-8ab9-4bef-ca28-9e036c54fae7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_desc</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How To Get Your Kids To Bed In A Few Dozen Eas...</td>\n",
       "      <td>Family &amp; Parenting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plus Size Models Are More Popular Than Ever B...</td>\n",
       "      <td>Home and Living lifestyle and beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HuffPost Workouts Songs to Help You Sleep Thes...</td>\n",
       "      <td>Health and Filtness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As Trump s Panel Seeks Personal Data These Lon...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Todd Akin Is Clapping For Donald Trump So That...</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title_desc  \\\n",
       "0  How To Get Your Kids To Bed In A Few Dozen Eas...   \n",
       "1   Plus Size Models Are More Popular Than Ever B...   \n",
       "2  HuffPost Workouts Songs to Help You Sleep Thes...   \n",
       "3  As Trump s Panel Seeks Personal Data These Lon...   \n",
       "4  Todd Akin Is Clapping For Donald Trump So That...   \n",
       "\n",
       "                                  class  \n",
       "0                    Family & Parenting  \n",
       "1  Home and Living lifestyle and beauty  \n",
       "2                   Health and Filtness  \n",
       "3                              Politics  \n",
       "4                              Politics  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url='https://dl.dropboxusercontent.com/s/gyjmd8se7669h15/complete_category_data.csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-zYq0kRJGK6"
   },
   "outputs": [],
   "source": [
    "# Data analysis and preparation\n",
    "# K Nearest Neighbors\n",
    "# Naive Bayes - MultinomialNB\n",
    "# AdaBoostClassifier\n",
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "EbrikFYsOnM2",
    "outputId": "a906a688-3498-4634-c44c-ce507c2b5f06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Media',\n",
       " 'Politics',\n",
       " 'Religion',\n",
       " 'Health and Filtness',\n",
       " 'Education',\n",
       " 'Business_FINANCE',\n",
       " 'Sports',\n",
       " 'Crime',\n",
       " 'SOCIETY',\n",
       " 'Home and Living lifestyle and beauty',\n",
       " 'Food & drink',\n",
       " 'Travel and Leisure',\n",
       " 'Environment',\n",
       " 'science and technology',\n",
       " 'automotive',\n",
       " 'Arts, Culture & Entertainment',\n",
       " 'Family & Parenting']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(df['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "XH-nvUNTzDW4",
    "outputId": "e9dd70fa-2744-4a64-faa9-795a7c7cec7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics                                29246\n",
       "Arts, Culture & Entertainment           22370\n",
       "Health and Filtness                     21834\n",
       "Home and Living lifestyle and beauty    14297\n",
       "Family & Parenting                      11240\n",
       "Travel and Leisure                       8795\n",
       "Food & drink                             7412\n",
       "Business_FINANCE                         6799\n",
       "SOCIETY                                  6353\n",
       "Sports                                   4338\n",
       "science and technology                   3777\n",
       "Crime                                    3047\n",
       "Media                                    2503\n",
       "Religion                                 2296\n",
       "automotive                               2163\n",
       "Education                                1914\n",
       "Environment                              1169\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts() # count vlaue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjVr1HRVFxu7"
   },
   "outputs": [],
   "source": [
    "n=int(df.shape[0] *0.25+0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g89IyJW8Bw7h"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data_YouTube = df.loc[:,['title_desc'  , 'class']]\n",
    "\n",
    "\n",
    "# Splitting the data into 0.25 training instances and 104 test instances\n",
    "all_Ids = np.arange(len(data_YouTube)) \n",
    "# random.shuffle(all_Ids)\n",
    "test_Ids = all_Ids[0:n]\n",
    "train_Ids = all_Ids[n:]\n",
    "data_test = data_YouTube.loc[test_Ids, :]\n",
    "data_train = data_YouTube.loc[train_Ids, :]\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train = count_vect.fit_transform(data_train['title_desc'])\n",
    "Y_train = data_train['class']\n",
    "\n",
    "X_test = count_vect.transform(data_test['title_desc'])\n",
    "Y_test = data_test['class'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "C00zdjlPQFLv",
    "outputId": "54df964b-25ea-4bf5-be6b-115b5cbf4537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112164, 71426)\n",
      "(112164,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LIZQXFJMQKvJ",
    "outputId": "f935a4f6-388f-4c1f-cd0c-5d3d5d6e9765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37389, 71426)\n",
      "(37389,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "LvuujZ-v3j0k",
    "outputId": "582fe26c-c54e-4d35-d4cb-06d24e86aa6c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VK-osnGdRBtm"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqd1SWsdQY5M"
   },
   "outputs": [],
   "source": [
    "# Assumptions:\n",
    "# 1. there is a linear relashionship between the logit of the outcome (dependent variable) and each predictor \n",
    "# variables (independent variables)\n",
    "#         logit(p) = log(p/(1-p))\n",
    "# 2. there is no outliers in the predictors. seaborn boxplot\n",
    "# 3. there is no co-relation between the dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "r-KZoxAETmie",
    "outputId": "1ec91149-5129-4921-ada4-7cce4c383e4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfyf_rYUUPzr"
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "NN_pred = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "8lrbIrnQUZhc",
    "outputId": "835b9f26-c9df-4945-aeff-48b3a3cd3fd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Health and Filtness', 'Arts, Culture & Entertainment',\n",
       "       'Arts, Culture & Entertainment', ..., 'Travel and Leisure',\n",
       "       'Health and Filtness', 'Media'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "nHCBmNhsUaxx",
    "outputId": "c1d5a96c-386b-488e-e6b7-48f69e870416"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          Family & Parenting\n",
       "1        Home and Living lifestyle and beauty\n",
       "2                         Health and Filtness\n",
       "3                                    Politics\n",
       "4                                    Politics\n",
       "                         ...                 \n",
       "37384                                Politics\n",
       "37385                                   Crime\n",
       "37386                        Business_FINANCE\n",
       "37387                  science and technology\n",
       "37388                                Politics\n",
       "Name: class, Length: 37389, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RfDfdnAtUd7x",
    "outputId": "4171128c-7311-49fc-850f-d4375c39d964"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25812404717965176"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,NN_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "A_8f48Z1VJTJ",
    "outputId": "882481d2-3017-478d-b505-cce0a53e6e56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4151,  390,   18,   34,    2,  116,   74,  471,   62,    9,  337,\n",
       "          29,    3,   12,   34,    0,    3],\n",
       "       [ 896,  277,    5,   20,    3,   60,   67,  232,   17,    9,  105,\n",
       "           7,    1,   12,   16,    0,    2],\n",
       "       [ 529,   47,   66,    7,    0,    7,   10,   55,    5,    0,   34,\n",
       "           2,    0,    1,    4,    0,    0],\n",
       "       [ 226,   38,    7,   49,    1,   25,   15,   64,    3,    1,   35,\n",
       "           3,    1,    1,    9,    0,    0],\n",
       "       [ 181,   23,    4,    7,   14,    7,    8,   34,    4,    0,   17,\n",
       "           7,    1,    0,    1,    0,    0],\n",
       "       [1330,  206,   43,   54,    3,  365,  110,  433,   42,    3,  117,\n",
       "          23,    4,   16,   35,    0,    6],\n",
       "       [ 931,  144,    6,   20,    0,   58,  256,  262,   38,    1,   73,\n",
       "          11,    0,    6,   19,    0,    1],\n",
       "       [2264,  476,   33,  106,    6,  318,  255, 1666,   79,    6,  264,\n",
       "          49,   17,   14,   36,    0,    4],\n",
       "       [1797,  222,   18,   45,    0,   80,  102,  451,  635,    2,  127,\n",
       "          15,    2,   15,   25,    0,    2],\n",
       "       [ 411,   42,    6,    9,    0,   14,    5,   51,    2,   21,   72,\n",
       "           2,    0,    2,    6,    0,    0],\n",
       "       [3894,  516,   38,   79,    1,  138,   86,  723,   50,   26, 1762,\n",
       "          36,    2,   21,   32,    0,    0],\n",
       "       [ 316,   37,    2,   12,    1,   34,   15,   58,    7,    0,   56,\n",
       "          44,    0,    1,    4,    0,    1],\n",
       "       [ 804,  117,   16,   27,    2,   86,   67,  250,   41,    3,   51,\n",
       "           9,  115,    8,   16,    0,    3],\n",
       "       [ 717,  104,   13,    8,    0,   21,   18,   93,    7,    2,   59,\n",
       "           3,    0,   37,    6,    0,    1],\n",
       "       [1123,  233,    8,   38,    2,   81,  110,  330,   46,    7,   97,\n",
       "          16,    6,   13,  166,    1,    3],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0],\n",
       "       [ 660,   71,    2,    8,    1,   19,   14,  116,    6,    2,   54,\n",
       "           6,    0,    2,    8,    0,   27]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "confusion_matrix(Y_test,NN_pred) #https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "9AxXgofYWS3u",
    "outputId": "cc4e519f-8ea9-449c-aa78-03bb62b78b19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alinemati/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "       Arts, Culture & Entertainment       0.21      0.72      0.32      5745\n",
      "                    Business_FINANCE       0.09      0.16      0.12      1729\n",
      "                               Crime       0.23      0.09      0.13       767\n",
      "                           Education       0.09      0.10      0.10       478\n",
      "                         Environment       0.39      0.05      0.08       308\n",
      "                  Family & Parenting       0.26      0.13      0.17      2790\n",
      "                        Food & drink       0.21      0.14      0.17      1826\n",
      "                 Health and Filtness       0.31      0.30      0.31      5593\n",
      "Home and Living lifestyle and beauty       0.61      0.18      0.28      3538\n",
      "                               Media       0.23      0.03      0.06       643\n",
      "                            Politics       0.54      0.24      0.33      7404\n",
      "                            Religion       0.17      0.07      0.10       588\n",
      "                             SOCIETY       0.76      0.07      0.13      1615\n",
      "                              Sports       0.23      0.03      0.06      1089\n",
      "                  Travel and Leisure       0.40      0.07      0.12      2280\n",
      "                          automotive       0.00      0.00      0.00         0\n",
      "              science and technology       0.51      0.03      0.05       996\n",
      "\n",
      "                            accuracy                           0.26     37389\n",
      "                           macro avg       0.31      0.14      0.15     37389\n",
      "                        weighted avg       0.37      0.26      0.24     37389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,NN_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gg4SFn5wY2ZE"
   },
   "source": [
    "# Naive Bayes - MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMAs1-OVaFTo"
   },
   "source": [
    "there is no co-relation between the dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TkUcQRr1WcGs",
    "outputId": "cad02861-f2a6-4a81-bd03-fd163f84f943"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCox1KVlZETX"
   },
   "outputs": [],
   "source": [
    "NB_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "yjHpdd0XZIyx",
    "outputId": "2e14b78e-8042-4687-c508-1d3c44e42f5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Family & Parenting', 'Home and Living lifestyle and beauty',\n",
       "       'Health and Filtness', ..., 'Travel and Leisure',\n",
       "       'science and technology', 'Politics'], dtype='<U36')"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "3OWGUxa5ZKOt",
    "outputId": "eb96942d-1bea-4abb-e5bb-67b17d9c02c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          Family & Parenting\n",
       "1        Home and Living lifestyle and beauty\n",
       "2                         Health and Filtness\n",
       "3                                    Politics\n",
       "4                                    Politics\n",
       "                         ...                 \n",
       "37384                                Politics\n",
       "37385                                   Crime\n",
       "37386                        Business_FINANCE\n",
       "37387                  science and technology\n",
       "37388                                Politics\n",
       "Name: class, Length: 37389, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gwdGD2zbZM8j",
    "outputId": "fd0ac9bc-82ba-4fcd-eae7-4b322d585df1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7082296932252802"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,NB_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "wb9H4_5CZfrF",
    "outputId": "2067f2d4-3515-4e08-dca3-b0e822b619bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4262,   18,   13,    2,    1,  210,   28,  287,  298,    0,  445,\n",
       "           1,   38,   11,  120,    1,   10],\n",
       "       [  65,  747,    6,    0,    0,   56,   18,  394,   34,    0,  332,\n",
       "           0,    6,    3,   45,   14,    9],\n",
       "       [  74,    5,  368,    0,    0,   45,    2,   22,    4,    0,  228,\n",
       "           0,    2,    2,   15,    0,    0],\n",
       "       [  21,   43,    8,   28,    0,   83,    1,  118,    6,    0,  162,\n",
       "           0,    0,    2,    5,    0,    1],\n",
       "       [  28,   14,    2,    0,   11,   21,    6,   59,   19,    0,   82,\n",
       "           0,    1,    0,   59,    1,    5],\n",
       "       [ 171,    9,    5,    1,    0, 1966,   14,  492,   46,    0,   50,\n",
       "           1,    6,    2,   25,    1,    1],\n",
       "       [  55,    9,    0,    0,    0,   55, 1290,  238,   55,    0,   20,\n",
       "           0,    4,    1,   99,    0,    0],\n",
       "       [ 119,   33,    2,    0,    0,  241,   95, 4807,   48,    1,  167,\n",
       "           1,   12,    6,   47,    1,   13],\n",
       "       [ 220,   35,    0,    0,    0,  104,   41,  273, 2717,    0,   38,\n",
       "           0,   22,    1,   84,    0,    3],\n",
       "       [ 118,   14,    2,    0,    0,    8,    1,   37,    9,   64,  379,\n",
       "           0,    1,    3,    4,    1,    2],\n",
       "       [ 229,   92,   43,    0,    2,   63,    3,  217,   20,    4, 6670,\n",
       "           1,    5,    9,   39,    0,    7],\n",
       "       [  75,    2,    5,    0,    0,   45,    4,  117,    4,    0,  228,\n",
       "          75,    4,    4,   24,    0,    1],\n",
       "       [ 136,    9,    0,    0,    0,  140,    8,  196,   83,    0,   34,\n",
       "           1,  986,    2,   20,    0,    0],\n",
       "       [ 252,   13,   15,    0,    0,   34,    2,   62,   12,    0,  150,\n",
       "           0,    3,  518,   27,    0,    1],\n",
       "       [  97,   23,    2,    1,    0,   68,   44,  192,   55,    0,   72,\n",
       "           0,    7,    4, 1712,    2,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0],\n",
       "       [ 118,   91,    1,    1,    0,   45,   11,  246,   33,    0,  127,\n",
       "           0,    8,    0,   48,    8,  259]])"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test,NB_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "CCsMbnY1Zk3p",
    "outputId": "43596b3c-ab0e-42fd-b0ba-a7b96d4fe89c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "       Arts, Culture & Entertainment       0.71      0.74      0.72      5745\n",
      "                    Business_FINANCE       0.65      0.43      0.52      1729\n",
      "                               Crime       0.78      0.48      0.59       767\n",
      "                           Education       0.85      0.06      0.11       478\n",
      "                         Environment       0.79      0.04      0.07       308\n",
      "                  Family & Parenting       0.62      0.70      0.66      2790\n",
      "                        Food & drink       0.82      0.71      0.76      1826\n",
      "                 Health and Filtness       0.62      0.86      0.72      5593\n",
      "Home and Living lifestyle and beauty       0.79      0.77      0.78      3538\n",
      "                               Media       0.93      0.10      0.18       643\n",
      "                            Politics       0.73      0.90      0.80      7404\n",
      "                            Religion       0.94      0.13      0.22       588\n",
      "                             SOCIETY       0.89      0.61      0.72      1615\n",
      "                              Sports       0.91      0.48      0.63      1089\n",
      "                  Travel and Leisure       0.72      0.75      0.74      2280\n",
      "                          automotive       0.00      0.00      0.00         0\n",
      "              science and technology       0.83      0.26      0.40       996\n",
      "\n",
      "                            accuracy                           0.71     37389\n",
      "                           macro avg       0.74      0.47      0.51     37389\n",
      "                        weighted avg       0.73      0.71      0.69     37389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,NB_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2iorNtiaOir"
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xY8yGoVuZ05y",
    "outputId": "0d2ef7f1-6d19-4042-b713-639c7f3f8e65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXLNfoTwae7y"
   },
   "outputs": [],
   "source": [
    "ada_pred = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "d3BrOAenalSC",
    "outputId": "8ca4adc3-9ec4-4eae-c9d7-9e9002efb622"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Family & Parenting', 'Health and Filtness', 'Health and Filtness',\n",
       "       ..., 'Politics', 'Health and Filtness', 'Politics'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "gn97-8tVamHv",
    "outputId": "56c94ddb-9dc4-45bd-ffa3-594b9f1b315c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          Family & Parenting\n",
       "1        Home and Living lifestyle and beauty\n",
       "2                         Health and Filtness\n",
       "3                                    Politics\n",
       "4                                    Politics\n",
       "                         ...                 \n",
       "37384                                Politics\n",
       "37385                                   Crime\n",
       "37386                        Business_FINANCE\n",
       "37387                  science and technology\n",
       "37388                                Politics\n",
       "Name: class, Length: 37389, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Us-1yAiRanmp",
    "outputId": "83fbc336-a081-4320-dc21-fb343ee1ddb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3163229826954452"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,ada_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "5bMYdh0Aas6M",
    "outputId": "c4e59b65-ec8f-4be0-89ec-af9cc316210e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  70,   31,   18,   28,    1,   49,    1, 4814,  148,    1,  520,\n",
       "           4,   45,    0,   15,    0,    0],\n",
       "       [   8,   83,    3,   32,    1,   25,    0, 1486,   14,    0,   57,\n",
       "           1,    4,    0,    6,    9,    0],\n",
       "       [   3,    4,  158,   12,    0,   23,    0,  551,    3,    0,    9,\n",
       "           0,    1,    0,    2,    1,    0],\n",
       "       [   3,    3,    8,  188,    0,   14,    0,  246,    2,    0,   14,\n",
       "           0,    0,    0,    0,    0,    0],\n",
       "       [   3,    2,    3,    3,    2,    3,    1,  210,   51,    0,   28,\n",
       "           0,    0,    0,    1,    1,    0],\n",
       "       [   5,   12,    2,   66,    0,  532,    4, 2041,   53,    2,   40,\n",
       "           2,   15,    0,   13,    3,    0],\n",
       "       [   3,   12,    0,    9,    0,   16,  254, 1408,  105,    0,    8,\n",
       "           0,    4,    0,    7,    0,    0],\n",
       "       [  21,   27,    3,   53,    0,   96,   13, 5174,   50,    1,  110,\n",
       "           0,   17,    0,   25,    3,    0],\n",
       "       [   7,   14,    1,    6,    0,   25,    2, 1958, 1455,    1,   31,\n",
       "           0,   27,    0,   11,    0,    0],\n",
       "       [   8,   17,    7,    2,    0,    3,    0,  378,    3,    2,  220,\n",
       "           1,    0,    0,    2,    0,    0],\n",
       "       [  31,   21,   86,  117,    0,   39,    0, 4486,    5,    0, 2559,\n",
       "          15,   24,    0,   19,    2,    0],\n",
       "       [   0,    1,    7,   11,    1,    0,    1,  466,    3,    0,   31,\n",
       "          60,    3,    0,    4,    0,    0],\n",
       "       [   6,    1,    1,    4,    0,   26,    1,  550,   46,    0,   11,\n",
       "           1,  965,    0,    3,    0,    0],\n",
       "       [   4,    2,    9,   25,    0,   14,    0,  982,   17,    0,   32,\n",
       "           0,    3,    0,    0,    1,    0],\n",
       "       [   6,    7,    2,   11,    1,   42,    4, 1486,  366,    0,   13,\n",
       "           0,   12,    0,  325,    5,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0],\n",
       "       [   5,   31,    4,    7,    0,   11,    0,  857,   30,    0,   37,\n",
       "           0,    1,    0,    6,    7,    0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test,ada_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "UFEp9T0lax95",
    "outputId": "8119e6e7-7d59-44f4-d233-4e43da8409dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "       Arts, Culture & Entertainment       0.38      0.01      0.02      5745\n",
      "                    Business_FINANCE       0.31      0.05      0.08      1729\n",
      "                               Crime       0.51      0.21      0.29       767\n",
      "                           Education       0.33      0.39      0.36       478\n",
      "                         Environment       0.33      0.01      0.01       308\n",
      "                  Family & Parenting       0.58      0.19      0.29      2790\n",
      "                        Food & drink       0.90      0.14      0.24      1826\n",
      "                 Health and Filtness       0.19      0.93      0.32      5593\n",
      "Home and Living lifestyle and beauty       0.62      0.41      0.49      3538\n",
      "                               Media       0.29      0.00      0.01       643\n",
      "                            Politics       0.69      0.35      0.46      7404\n",
      "                            Religion       0.71      0.10      0.18       588\n",
      "                             SOCIETY       0.86      0.60      0.71      1615\n",
      "                              Sports       0.00      0.00      0.00      1089\n",
      "                  Travel and Leisure       0.74      0.14      0.24      2280\n",
      "                          automotive       0.00      0.00      0.00         0\n",
      "              science and technology       0.00      0.00      0.00       996\n",
      "\n",
      "                            accuracy                           0.32     37389\n",
      "                           macro avg       0.44      0.21      0.22     37389\n",
      "                        weighted avg       0.50      0.32      0.28     37389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,ada_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2_MMWbVbH7M"
   },
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSjDRORbcAR_"
   },
   "source": [
    "We should have huge training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "jIC2nm6ga8jj",
    "outputId": "93d221e8-5c8f-4406-b260-bb4c91a7e034"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                     oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "EX_3 = ExtraTreesClassifier()\n",
    "EX_3.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbXD_dVwbQbc"
   },
   "outputs": [],
   "source": [
    "EX_3_pred = EX_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bSMxE2BpbVvS",
    "outputId": "49d26388-6a2a-4e80-9750-7bbfa4351344"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5919922971997111"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,EX_3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "Ncfm53aybbBb",
    "outputId": "8a27f177-7e79-4923-ce29-d1215ccd4371"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4147,   45,   29,    8,    2,  153,   55,  382,  180,    9,  629,\n",
       "          10,   30,   18,   35,    5,    8],\n",
       "       [ 315,  371,   13,    8,    4,   59,   41,  429,   47,    3,  379,\n",
       "           1,    9,   11,   21,    7,   11],\n",
       "       [ 140,    6,  328,    5,    0,   31,    4,   49,    7,    1,  167,\n",
       "           2,    0,    6,   19,    2,    0],\n",
       "       [  73,   20,    8,   87,    0,   51,    7,  100,    9,    0,  111,\n",
       "           1,    5,    2,    3,    0,    1],\n",
       "       [  69,   17,    1,    3,   29,   11,    9,   63,   21,    0,   70,\n",
       "           0,    2,    1,   10,    0,    2],\n",
       "       [ 427,   36,   11,   18,    0, 1468,   43,  511,   93,    0,  127,\n",
       "           2,   26,    7,   19,    1,    1],\n",
       "       [ 300,   33,    0,    4,    0,   56, 1015,  233,   85,    0,   59,\n",
       "           2,    2,    3,   32,    1,    1],\n",
       "       [ 590,   82,    7,   16,    2,  300,  147, 4003,   97,    3,  265,\n",
       "           4,   15,   11,   39,    4,    8],\n",
       "       [ 622,   41,    5,    1,    1,   95,  106,  341, 2130,    1,  115,\n",
       "           0,   25,    3,   40,    8,    4],\n",
       "       [ 151,   15,   11,    2,    0,   18,    3,   46,    9,   86,  289,\n",
       "           1,    1,    7,    3,    0,    1],\n",
       "       [ 541,   75,   80,   28,    1,   69,   26,  316,   30,   12, 6170,\n",
       "           7,    4,    9,   27,    4,    5],\n",
       "       [ 127,   11,    8,    2,    0,   34,    7,  109,   14,    2,  153,\n",
       "         103,    1,    8,    5,    0,    4],\n",
       "       [ 198,   13,    4,    1,    0,  132,   20,  234,   96,    0,   63,\n",
       "           0,  837,    3,   11,    3,    0],\n",
       "       [ 410,   19,   16,    7,    1,   27,    5,   74,   17,    5,  191,\n",
       "           0,    2,  302,   11,    0,    2],\n",
       "       [ 397,   49,    7,    4,    1,   95,   97,  367,  186,    1,  152,\n",
       "           3,   18,    8,  883,   10,    2],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0],\n",
       "       [ 280,   55,    8,    3,    0,   32,   30,  211,   38,    2,  126,\n",
       "           0,    0,    9,   23,    4,  175]])"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test,EX_3_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXLSkuqEdhSJ"
   },
   "source": [
    "# Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3B155rfydU0b"
   },
   "outputs": [],
   "source": [
    "NN_ACC=accuracy_score(Y_test,NN_pred)\n",
    "NB_ACC=accuracy_score(Y_test,NB_pred)\n",
    "ada_ACC=accuracy_score(Y_test,ada_pred)\n",
    "EX_3_ACC=accuracy_score(Y_test,EX_3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "9lNwPec2eaDO",
    "outputId": "82ba083a-dab9-4f7c-9128-8c02b812c40f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25812404717965176,\n",
       " 0.7082296932252802,\n",
       " 0.3163229826954452,\n",
       " 0.5919922971997111]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[NN_ACC, NB_ACC, ada_ACC, EX_3_ACC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "Kbje43E9egtk",
    "outputId": "a359e683-d757-45ba-b64c-87a0d68b923d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots() \n",
    "ax.set_xticks(np.arange(4))\n",
    "ax.set_xticklabels([\"NN\",\"NB\",\"ada\",\"EX_3\"])\n",
    "plt.bar(range(4),[NN_ACC, NB_ACC, ada_ACC, EX_3_ACC] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "0dM4Lhnhe7Pf",
    "outputId": "e2e97898-ec1d-41c1-e42a-45fa588fe2f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('EX_3',\n",
       "                              ExtraTreesClassifier(bootstrap=False,\n",
       "                                                   class_weight=None,\n",
       "                                                   criterion='gini',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=10, n_jobs=None,\n",
       "                                                   oob_score=False,\n",
       "                                                   random_state=None, verbose=0,\n",
       "                                                   warm_start=False)),\n",
       "                             ('NB',\n",
       "                              MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                            fit_prior=True))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voter = VotingClassifier(estimators=[('EX_3',EX_3),('NB',clf)],voting='soft')\n",
    "voter.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXtUW35LfxT7"
   },
   "outputs": [],
   "source": [
    "voter_pred = voter.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qZ5UukWif2nk",
    "outputId": "c1b80752-f1ba-45b6-c390-bcadb4734d26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7127764850624515"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,voter_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FSGguAnAf50p"
   },
   "outputs": [],
   "source": [
    "\"Done\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Document Classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
